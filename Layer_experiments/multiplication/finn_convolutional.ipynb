{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'qonnx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c1a315676740>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0monnx\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhelper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensorProto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mqonnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_datatypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInferDataTypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mqonnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_shapes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInferShapes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ONNX version:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'qonnx'"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx.shape_inference import infer_shapes\n",
    "from onnx import helper, TensorProto\n",
    "import os\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.custom_op.general.im2col import compute_conv_output_dim\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.util.basic import gen_finn_dt_tensor\n",
    "\n",
    "print(\"ONNX version:\", onnx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size, stride, pad = 3,1,0\n",
    "group = 1\n",
    "in_feature_dim = 7\n",
    "in_chn = 16\n",
    "out_chn = 20\n",
    "conv_param_shape = [out_chn, in_chn, kernel_size, kernel_size]\n",
    "idt = DataType[\"UINT4\"]\n",
    "\n",
    "total_pad = 2 * pad\n",
    "out_feature_dim = compute_conv_output_dim(\n",
    "    in_feature_dim, kernel_size, stride, total_pad\n",
    ")\n",
    "\n",
    "input_shape = [1, in_chn, in_feature_dim, in_feature_dim]\n",
    "output_shape = [1, out_chn, out_feature_dim, out_feature_dim]\n",
    "\n",
    "conv_weight_dt = DataType[\"UINT4\"]\n",
    "\n",
    "conv_config = {}\n",
    "conv_config[\"dilations\"] = [1, 1]\n",
    "conv_config[\"group\"] = group\n",
    "conv_config[\"kernel_shape\"] = [kernel_size, kernel_size]\n",
    "conv_config[\"pads\"] = [pad, pad, pad, pad]\n",
    "conv_config[\"strides\"] = [stride, stride]\n",
    "\n",
    "top_in = helper.make_tensor_value_info(\"top_in\", TensorProto.FLOAT, input_shape)\n",
    "top_out = helper.make_tensor_value_info(\"top_out\", TensorProto.FLOAT, output_shape)\n",
    "value_info = [\n",
    "    helper.make_tensor_value_info(\"p1\", TensorProto.FLOAT, conv_param_shape)\n",
    "]\n",
    "\n",
    "modelproto = helper.make_model(\n",
    "    helper.make_graph(\n",
    "        name=\"conv_test\",\n",
    "        inputs=[top_in],\n",
    "        outputs=[top_out],\n",
    "        value_info=value_info,\n",
    "        nodes=[\n",
    "            helper.make_node(\"Conv\", [\"top_in\", \"p1\"], [\"top_out\"], **conv_config)\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "model = ModelWrapper(modelproto)\n",
    "model.set_tensor_datatype(\"top_in\", idt)\n",
    "model.set_tensor_datatype(\"top_out\", idt)\n",
    "model.set_tensor_datatype(\"p1\", conv_weight_dt)\n",
    "model.set_initializer(\"p1\", gen_finn_dt_tensor(conv_weight_dt, conv_param_shape))\n",
    "\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(InferDataTypes())\n",
    "\n",
    "onnx.save(model,\"convolutional_model.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0480a40de60fe0b4be044949303dbe98ce3610184aeb132e77bccbcbbb8df2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
