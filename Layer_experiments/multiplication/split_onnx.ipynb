{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx.shape_inference import infer_shapes, infer_shapes_path\n",
    "from onnx import helper\n",
    "onnx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audioop import mul\n",
    "\n",
    "\n",
    "model = onnx.load(\"tinyyolo_infershapes.onnx\")\n",
    "mulnodes = []\n",
    "for index,n in enumerate(model.graph.node):\n",
    "    if \"Mul_\" in n.name:\n",
    "        mulnodes.append(index)\n",
    "\n",
    "mul_node = model.graph.node[mulnodes[0]]\n",
    "in_tensors = mul_node.input\n",
    "out_tensor = mul_node.output\n",
    "in_value_info = []\n",
    "out_value_info = []\n",
    "\n",
    "for x in model.graph.value_info:\n",
    "    if in_tensors[0] in x.name or in_tensors[1] in x.name:\n",
    "        in_value_info.append(x)\n",
    "    elif out_tensor[0] in x.name:\n",
    "        out_value_info.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Make a graph from the node that I have extracted...\n",
    "graph = helper.make_graph(\n",
    "    nodes=[mul_node],\n",
    "    name=\"simple_graph\",\n",
    "    inputs=[in_value_info[0], in_value_info[1]],\n",
    "    # initializer = [in_value_info[1]],\n",
    "    outputs=[out_value_info[0]],\n",
    ")\n",
    "\n",
    "onnx_model = helper.make_model(graph, producer_name=\"multiply-model\")\n",
    "onnx.save(onnx_model, 'multiply_model_split.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "in1 = np.random.random([1,3,512,512]).astype(np.float32)\n",
    "b = np.random.random([1]).astype(np.float32)\n",
    "# out_ort = np.random.random([1,16,512,512]).astype(np.float32)\n",
    "output = in1*b\n",
    "\n",
    "input_dict = {\"278\": in1, \"279\": b}\n",
    "sess = ort.InferenceSession(onnx_model.SerializeToString())\n",
    "out_ort = sess.run(None,input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(out_ort,output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0480a40de60fe0b4be044949303dbe98ce3610184aeb132e77bccbcbbb8df2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
