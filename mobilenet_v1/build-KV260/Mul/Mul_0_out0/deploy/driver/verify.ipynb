{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "import onnxruntime as ort\n",
    "from onnx import helper\n",
    "from onnxruntime_extensions import get_library_path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 32, 111, 111]\n",
      "(1, 111, 111, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[846, 623, 499, 451, 556]], dtype=int64)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def revert_quantAvgPool(model):\n",
    "    nodes = [n for n in model.graph.node if n.op_type == 'QuantAvgPool2d']\n",
    "    attrs = [n.attribute for n in model.graph.node if n.op_type == 'QuantAvgPool2d']\n",
    "    for node,attr in zip(nodes,attrs):\n",
    "        for a in attr:\n",
    "            if a.name == \"stride\":\n",
    "                s = a.i\n",
    "            elif a.name == \"kernel\":\n",
    "                k = a.i\n",
    "        update = helper.make_node(\n",
    "            \"AveragePool\",\n",
    "            inputs=[node.input[0]],\n",
    "            outputs=[node.output[0]],\n",
    "            kernel_shape=[k,k],\n",
    "            strides=[s,s],\n",
    "        )\n",
    "\n",
    "        model.graph.node.remove(node)\n",
    "        model.graph.node.append(update)\n",
    "        \n",
    "def set_multithreshold_default(model,save_model):\n",
    "\n",
    "    new_attr = [helper.make_attribute(\"out_scale\", 1.0),\n",
    "                helper.make_attribute(\"out_bias\", 0.0),\n",
    "                helper.make_attribute(\"data_layout\",\"NCHW\")]\n",
    "\n",
    "    for n in model.graph.node:\n",
    "        if n.op_type == \"MultiThreshold\":\n",
    "            out_scale,bias,datalayout = False,False,False\n",
    "            for na in n.attribute:\n",
    "                if na.name == \"out_scale\": out_scale = True\n",
    "                if na.name == \"out_bias\": bias = True\n",
    "                if na.name == \"data_layout\": datlayout = True\n",
    "            if not out_scale: n.attribute.append(new_attr[0])\n",
    "            if not bias: n.attribute.append(new_attr[1])\n",
    "            if not datalayout: n.attribute.append(new_attr[2])\n",
    "\n",
    "            n.domain = \"ai.onnx.contrib\"\n",
    "    model.save(mfile_up)\n",
    "\n",
    "def ort_implementation(x,model):\n",
    "    so = ort.SessionOptions()\n",
    "    so.register_custom_ops_library(get_library_path())\n",
    "\n",
    "    sess = ort.InferenceSession(mfile_up, so)\n",
    "    print(sess.get_inputs()[0].shape)\n",
    "    print(x.shape)\n",
    "    expect_inp_shape = sess.get_inputs()[0].shape\n",
    "    x = np.reshape(x,tuple(expect_inp_shape))\n",
    "    inp_dict = {}\n",
    "    for inp in sess.get_inputs():\n",
    "        inp_dict[inp.name] = x\n",
    "    res = sess.run([],inp_dict)\n",
    "    return res   \n",
    "\n",
    "\n",
    "model_dir = \"../../../../../../models/estimate/Mul/Mul_0_out0/\"\n",
    "mfile = model_dir+\"partition_1.onnx\"\n",
    "mfile_up = mfile.replace(\".onnx\",\"_ort.onnx\")\n",
    "\n",
    "model = ModelWrapper(mfile)\n",
    "revert_quantAvgPool(model)\n",
    "set_multithreshold_default(model,mfile_up)\n",
    "ort_out = ort_implementation(np.load(\"output.npy\"),model)\n",
    "# np.save(model_dir +\"ort_out.npy\",ort_out)\n",
    "ort_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from qonnx.core.datatype import DataType\n",
    "from driver_base import FINNExampleOverlay\n",
    "\n",
    "input_file = \"../../../../../../models/estimate/Mul/Mul_0_out0/input.npy\"\n",
    "x = np.load(input_file)\n",
    "x = x.reshape([1,224,224,3]).astype(np.int8)\n",
    "print(x.dtype)\n",
    "np.save(\"../../../../../../models/estimate/Mul/Mul_0_out0/input_hw.npy\",x)\n",
    "# deploy_dir = 'build-KV260/fit/Mul/Mul_0_out0/deploy'\n",
    "! python driver.py --bitfile=\"../bitfile/finn-accel.bit\" --inputfile=\"../../../../../../models/estimate/Mul/Mul_0_out0/input_hw.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HW: (1, 111, 111, 32)\n",
      "ORT: (1, 1, 32, 111, 111)\n",
      "ORT: (1, 111, 111, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]],\n",
       "\n",
       "        [[False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False],\n",
       "         [False, False, False, ..., False, False, False]]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_hw = np.load(\"output.npy\")\n",
    "print(\"HW:\", out_hw.shape)\n",
    "ort_out = np.load(model_dir+\"ort_out.npy\")\n",
    "print(\"ORT:\", ort_out.shape)\n",
    "\n",
    "ort_out = np.reshape(ort_out,out_hw.shape,order='a')\n",
    "print(\"ORT:\", out_hw.shape)\n",
    "np.isclose(out_hw,ort_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
