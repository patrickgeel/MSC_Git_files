{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU_testing/MultiThreshold_0_out0\n",
      "CPU_testing/MultiThreshold_1_out0\n",
      "CPU_testing/MultiThreshold_2_out0\n",
      "CPU_testing/MultiThreshold_3_out0\n",
      "CPU_testing/MultiThreshold_4_out0\n",
      "CPU_testing/MultiThreshold_5_out0\n",
      "CPU_testing/MultiThreshold_6_out0\n",
      "CPU_testing/MultiThreshold_7_out0\n",
      "CPU_testing/MultiThreshold_8_out0\n",
      "CPU_testing/MultiThreshold_9_out0\n",
      "CPU_testing/MultiThreshold_10_out0\n",
      "CPU_testing/MultiThreshold_11_out0\n",
      "CPU_testing/MultiThreshold_12_out0\n",
      "CPU_testing/MultiThreshold_13_out0\n",
      "CPU_testing/MultiThreshold_14_out0\n",
      "CPU_testing/MultiThreshold_15_out0\n",
      "CPU_testing/MultiThreshold_16_out0\n",
      "CPU_testing/MultiThreshold_17_out0\n",
      "CPU_testing/MultiThreshold_18_out0\n",
      "CPU_testing/MultiThreshold_19_out0\n",
      "CPU_testing/MultiThreshold_20_out0\n",
      "CPU_testing/MultiThreshold_21_out0\n",
      "CPU_testing/MultiThreshold_22_out0\n",
      "CPU_testing/MultiThreshold_23_out0\n",
      "CPU_testing/MultiThreshold_24_out0\n",
      "CPU_testing/MultiThreshold_25_out0\n",
      "CPU_testing/MultiThreshold_26_out0\n"
     ]
    }
   ],
   "source": [
    "from qonnx.util.basic import get_by_name\n",
    "from qonnx.transformation.create_generic_partitions import PartitionFromDict\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "import os\n",
    "\n",
    "model = ModelWrapper(\"/home/pgeel/FINNv0.8.1_repo/build_KV260/finn/notebooks/MSC_Git_files/mobilenet_v1/models/mobilenet_streamline.onnx\")\n",
    "splits = []\n",
    "for n in model.graph.node:\n",
    "    if n.op_type == 'MultiThreshold':\n",
    "        splits.append(n.output[0])\n",
    "\n",
    "def custom_step_partition(stop_node):\n",
    "    output_dir = os.path.join(\"CPU_testing\",stop_node)\n",
    "    print(output_dir)\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    upstream_0 = model.find_upstream(stop_node, lambda x: x.name == \"Conv_0\")\n",
    "    wanted_nodes = []\n",
    "    unwanted_nodes = []\n",
    "    for ind, node in enumerate(model.graph.node):\n",
    "        found_0 = get_by_name(upstream_0, node.name, \"name\") is not None\n",
    "        if found_0:\n",
    "            wanted_nodes.append(ind)\n",
    "        else:\n",
    "            unwanted_nodes.append(ind)\n",
    "    parent=model.transform(PartitionFromDict(\n",
    "        partitioning={ 0 : wanted_nodes, 1 : unwanted_nodes }, \n",
    "        partition_dir= output_dir\n",
    "    ))\n",
    "#     return ModelWrapper(output_dir+\"/partition_1.onnx\")\n",
    "\n",
    "for s in splits:\n",
    "    custom_step_partition(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnxruntime_extensions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ff1a04ba1095>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mqonnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodelwrapper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelWrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0monnxruntime_extensions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_library_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPyOp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monnx_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPyOrtFunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0monnxruntime\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0monnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'onnxruntime_extensions'"
     ]
=======
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MultiThreshold_6_out0': {'runtime[ms]': 208.67419242858887,\n",
       "   '# of nodes': 45}},\n",
       " {'MultiThreshold_13_out0': {'runtime[ms]': 139.74952697753906,\n",
       "   '# of nodes': 31}},\n",
       " {'MultiThreshold_17_out0': {'runtime[ms]': 94.49982643127441,\n",
       "   '# of nodes': 23}},\n",
       " {'MultiThreshold_12_out0': {'runtime[ms]': 146.98123931884766,\n",
       "   '# of nodes': 33}},\n",
       " {'MultiThreshold_2_out0': {'runtime[ms]': 290.996789932251,\n",
       "   '# of nodes': 53}},\n",
       " {'MultiThreshold_21_out0': {'runtime[ms]': 50.43387413024902,\n",
       "   '# of nodes': 15}},\n",
       " {'MultiThreshold_19_out0': {'runtime[ms]': 76.78008079528809,\n",
       "   '# of nodes': 19}},\n",
       " {'MultiThreshold_26_out0': {'runtime[ms]': 1.6369819641113281,\n",
       "   '# of nodes': 5}},\n",
       " {'MultiThreshold_0_out0': {'runtime[ms]': 352.51426696777344,\n",
       "   '# of nodes': 57}},\n",
       " {'MultiThreshold_22_out0': {'runtime[ms]': 34.74879264831543,\n",
       "   '# of nodes': 13}},\n",
       " {'MultiThreshold_3_out0': {'runtime[ms]': 278.28192710876465,\n",
       "   '# of nodes': 51}},\n",
       " {'MultiThreshold_9_out0': {'runtime[ms]': 177.2153377532959,\n",
       "   '# of nodes': 39}},\n",
       " {'MultiThreshold_18_out0': {'runtime[ms]': 80.85107803344727,\n",
       "   '# of nodes': 21}},\n",
       " {'MultiThreshold_10_out0': {'runtime[ms]': 158.0197811126709,\n",
       "   '# of nodes': 37}},\n",
       " {'MultiThreshold_8_out0': {'runtime[ms]': 199.4338035583496,\n",
       "   '# of nodes': 41}},\n",
       " {'MultiThreshold_25_out0': {'runtime[ms]': 19.22750473022461,\n",
       "   '# of nodes': 7}},\n",
       " {'MultiThreshold_5_out0': {'runtime[ms]': 239.6845817565918,\n",
       "   '# of nodes': 47}},\n",
       " {'MultiThreshold_20_out0': {'runtime[ms]': 58.74896049499512,\n",
       "   '# of nodes': 17}},\n",
       " {'MultiThreshold_23_out0': {'runtime[ms]': 32.67478942871094,\n",
       "   '# of nodes': 11}},\n",
       " {'MultiThreshold_7_out0': {'runtime[ms]': 201.92742347717285,\n",
       "   '# of nodes': 43}},\n",
       " {'MultiThreshold_24_out0': {'runtime[ms]': 23.531198501586914,\n",
       "   '# of nodes': 9}},\n",
       " {'MultiThreshold_15_out0': {'runtime[ms]': 117.67840385437012,\n",
       "   '# of nodes': 27}},\n",
       " {'MultiThreshold_11_out0': {'runtime[ms]': 153.69057655334473,\n",
       "   '# of nodes': 35}},\n",
       " {'MultiThreshold_4_out0': {'runtime[ms]': 259.4790458679199,\n",
       "   '# of nodes': 49}},\n",
       " {'MultiThreshold_16_out0': {'runtime[ms]': 106.2779426574707,\n",
       "   '# of nodes': 25}},\n",
       " {'MultiThreshold_14_out0': {'runtime[ms]': 130.07807731628418,\n",
       "   '# of nodes': 29}},\n",
       " {'MultiThreshold_1_out0': {'runtime[ms]': 345.26824951171875,\n",
       "   '# of nodes': 55}}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> ec9f47686f80f50f390fe7e28d9a6034393d88a6
    }
   ],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from onnxruntime_extensions import get_library_path, PyOp, onnx_op, PyOrtFunction\n",
    "import os\n",
    "import onnxruntime as ort\n",
    "import onnx\n",
    "import numpy as np\n",
    "import time\n",
    "from onnx import helper\n",
    "from qonnx.transformation.double_to_single_float import DoubleToSingleFloat\n",
    "import pandas as pd\n",
    "\n",
    "# CPU_TESTING\n",
    "total = []\n",
    "so = ort.SessionOptions()\n",
    "so.register_custom_ops_library(get_library_path())\n",
    "\n",
    "def set_multithreshold_default(model):#,save_model):\n",
    "    '''\n",
    "    Pass a modelproto model and the save file\n",
    "    '''\n",
    "    model = model.transform(DoubleToSingleFloat())\n",
    "    new_attr = [helper.make_attribute(\"out_scale\", 1.0),\n",
    "                helper.make_attribute(\"out_bias\", 0.0),\n",
    "                helper.make_attribute(\"data_layout\",\"NCHW\")]\n",
    "\n",
    "    for n in model.graph.node:\n",
    "        if n.op_type == \"MultiThreshold\":\n",
    "            out_scale,bias,datalayout = False,False,False\n",
    "            for na in n.attribute:\n",
    "                if na.name == \"out_scale\": out_scale = True\n",
    "                if na.name == \"out_bias\": bias = True\n",
    "                if na.name == \"data_layout\": datlayout = True\n",
    "            if not out_scale: n.attribute.append(new_attr[0])\n",
    "            if not bias: n.attribute.append(new_attr[1])\n",
    "            if not datalayout: n.attribute.append(new_attr[2])\n",
    "\n",
    "            n.domain = \"ai.onnx.contrib\"\n",
    "#     model.save(save_model)\n",
    "    return model\n",
    "\n",
    "def size_model(model):\n",
    "    cnt = 0\n",
    "    for n in model.graph.node:\n",
    "        cnt +=1\n",
    "    return cnt\n",
    "for j in os.listdir(\"CPU_testing\"):\n",
    "    rt = {}\n",
    "    if os.path.isdir(os.path.join(\"CPU_testing\",os.path.relpath(j))):\n",
    "        file = os.path.join(\"CPU_testing\",os.path.relpath(j),\"partition_1.onnx\")\n",
    "    #     Place onnx runtime code here, need to generate dummy data to pass to the onnx graph.\n",
    "        model = ModelWrapper(file)\n",
    "        model = set_multithreshold_default(model)\n",
    "\n",
    "        sess = ort.InferenceSession(model.model.SerializeToString(),so)\n",
    "        x = np.random.randint(0,255,sess.get_inputs()[0].shape).astype(np.float32)\n",
    "        start = time.time()\n",
    "        res = sess.run([],{sess.get_inputs()[0].name:x})\n",
    "        end = time.time()\n",
<<<<<<< HEAD
    "        rt[size_model(model)] = {j,(end-start)*1e3}\n",
    "rt"
=======
    "        rt[j] = {\"runtime[ms]\":(end-start)*1e3,\"# of nodes\": size_model(model)}\n",
    "        total.append(rt)\n",
    "total"
>>>>>>> ec9f47686f80f50f390fe7e28d9a6034393d88a6
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"CPU_testing/runtimes.json\",'w') as f:\n",
    "    json.dump(total,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "c0480a40de60fe0b4be044949303dbe98ce3610184aeb132e77bccbcbbb8df2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
