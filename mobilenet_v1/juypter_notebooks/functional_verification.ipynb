{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bd89c3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/juypter_notebooks', '/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/src/qonnx', '/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/src/finn', '/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/src', '/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/src/qonnx', '/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/src/finn', '/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/src', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/share/pynq-venv/lib/python3.10/site-packages', '/usr/local/lib/python3.10/dist-packages', '/usr/local/lib/python3.10/dist-packages/onnx-1.12.0-py3.10-linux-aarch64.egg', '/usr/local/lib/python3.10/dist-packages/typing_extensions-4.4.0-py3.10.egg', '/usr/local/lib/python3.10/dist-packages/qonnx-0.0.0-py3.10.egg', '/usr/local/lib/python3.10/dist-packages/toposort-1.7-py3.10.egg', '/usr/local/lib/python3.10/dist-packages/sigtools-2.0.3-py3.10.egg', '/usr/local/lib/python3.10/dist-packages/onnxruntime_extensions-0.5.0+1762059-py3.10-linux-aarch64.egg', '/usr/lib/python3/dist-packages', '/usr/lib/python3.10/dist-packages', '/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/build-KV260/Conv/Conv_6_out0/driver']\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import os\n",
    "# sys.path = []\n",
    "sys.path.insert(1,os.path.abspath(\"../src/\"))\n",
    "sys.path.insert(1,os.path.abspath(\"../src/finn/\"))\n",
    "sys.path.insert(1,os.path.abspath(\"../src/qonnx/\"))\n",
    "print(sys.path)\n",
    "clean_sys_path = sys.path\n",
    "\n",
    "def print_name(key):\n",
    "    print(\"--\"*20,key, \"--\"*20)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddec9c0",
   "metadata": {},
   "source": [
    "# Create dummy inputs and store in the correct model directory \n",
    "For the moment want to create dummy input data, and keep this constant such that it does not change. Use this data to verify that the hw + cpu run has the same output as the expected output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "06dc8f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- Conv_6_out0 ----------------------------------------\n",
      "bitfile  driver\t\t   partition_0_ort.onnx  partition_1_ort.onnx\n",
      "data\t partition_0.onnx  partition_1.onnx\n",
      "---------------------------------------- Conv_10_out0 ----------------------------------------\n",
      "bitfile  driver\t\t   partition_0_ort.onnx  partition_1_ort.onnx\n",
      "data\t partition_0.onnx  partition_1.onnx\n",
      "---------------------------------------- Conv_0_out0 ----------------------------------------\n",
      "bitfile  driver\t\t   partition_0_ort.onnx  partition_1_ort.onnx\n",
      "data\t partition_0.onnx  partition_1.onnx\n",
      "---------------------------------------- Conv_2_out0 ----------------------------------------\n",
      "bitfile  driver\t\t   partition_0_ort.onnx  partition_1_ort.onnx\n",
      "data\t partition_0.onnx  partition_1.onnx\n",
      "---------------------------------------- Conv_4_out0 ----------------------------------------\n",
      "bitfile  driver\t\t   partition_0_ort.onnx  partition_1_ort.onnx\n",
      "data\t partition_0.onnx  partition_1.onnx\n",
      "---------------------------------------- Conv_8_out0 ----------------------------------------\n",
      "bitfile  driver\t\t   partition_0_ort.onnx  partition_1_ort.onnx\n",
      "data\t partition_0.onnx  partition_1.onnx\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "clear_data = False\n",
    "\n",
    "# Create a directory with relative info\n",
    "model_dict = {}\n",
    "\n",
    "# Get the onnx model directory\n",
    "md = os.path.abspath(\"../models\")\n",
    "op_type = \"Conv\"\n",
    "\n",
    "# Get the model hw directory where the driver file is located.\n",
    "build_dir = os.path.abspath(\"../build-KV260/\")\n",
    "\n",
    "# Get split names for created hw files\n",
    "split_dirs = [s for s in os.listdir(os.path.join(build_dir,op_type))]\n",
    "\n",
    "# Fill the model dict\n",
    "for split_name in split_dirs:\n",
    "    print_name(split_name)\n",
    "    model_base_folder = os.path.join(md,op_type,split_name)\n",
    "    driver_dir = os.path.join(model_base_folder,\"driver\")\n",
    "    bitfile_dir = os.path.join(model_base_folder,\"bitfile\")\n",
    "    data_dir = os.path.join(model_base_folder,\"data\")\n",
    "    if clear_data:\n",
    "        try:\n",
    "            shutil.rmtree(data_dir)\n",
    "            shutil.rmtree(bitfile_dir)\n",
    "            shutil.rmtree(driver_dir)\n",
    "        except OSError as e:\n",
    "            pass        \n",
    "    else:\n",
    "        shutil.copytree(os.path.join(build_dir,op_type,split_name,\"deploy\"),\n",
    "                        model_base_folder, \n",
    "                        dirs_exist_ok=True\n",
    "                       )\n",
    "        \n",
    "    ! ls {model_base_folder}\n",
    "    model_dict[split_name.replace('_out0','')] = {\"model_dir\": model_base_folder, \n",
    "                                                  \"driver_dir\": driver_dir, \n",
    "                                                  \"bitfile_dir\":bitfile_dir,\n",
    "                                                  \"data_dir\": data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957c181d",
   "metadata": {},
   "source": [
    "##### Eventually want to supply a image and see the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2249e336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_6_gld_output.npy  Conv_6_hw_output.npy  Conv_6_output.npy\n",
      "Conv_6_hw_input.npy    Conv_6_input.npy\n",
      "Conv_10_gld_output.npy\tConv_10_hw_output.npy  Conv_10_output.npy\n",
      "Conv_10_hw_input.npy\tConv_10_input.npy\n",
      "Conv_0_gld_output.npy  Conv_0_hw_output.npy  Conv_0_output.npy\n",
      "Conv_0_hw_input.npy    Conv_0_input.npy\n",
      "Conv_2_gld_output.npy  Conv_2_hw_output.npy  Conv_2_output.npy\n",
      "Conv_2_hw_input.npy    Conv_2_input.npy\n",
      "Conv_4_gld_output.npy  Conv_4_hw_output.npy  Conv_4_output.npy\n",
      "Conv_4_hw_input.npy    Conv_4_input.npy\n",
      "Conv_8_gld_output.npy  Conv_8_hw_output.npy  Conv_8_output.npy\n",
      "Conv_8_hw_input.npy    Conv_8_input.npy\n"
     ]
    }
   ],
   "source": [
    "# Create dummy data for the moment\n",
    "for k,v in model_dict.items():\n",
    "    sd = v[\"data_dir\"]\n",
    "    if not os.path.exists(sd):\n",
    "        os.mkdir(sd)\n",
    "        x = np.random.random([1,3,224,224])\n",
    "        np.save(f\"{sd}/{k}_input.npy\",x)\n",
    "        v[\"data_dir\"] = sd\n",
    "    ! ls {v[\"data_dir\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a240b91",
   "metadata": {},
   "source": [
    "# Get golden output \n",
    "For each of the inputs get the expected output from the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9d4388f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 224, 224]\n",
      "[array([[644, 818, 530, 111, 626]], dtype=int64)]\n",
      "[array([[644, 818, 111, 530, 626]], dtype=int64)]\n",
      "[array([[644, 818, 111, 530, 626]], dtype=int64)]\n",
      "[array([[644, 818, 530, 111, 626]], dtype=int64)]\n",
      "[array([[644, 818, 530, 111, 626]], dtype=int64)]\n",
      "[array([[644, 818, 530, 626, 111]], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from onnxruntime_extensions import get_library_path\n",
    "import onnxruntime as ort\n",
    "# from custom_ort_functions import set_multithreshold_default\n",
    "\n",
    "# Load input streamlined model\n",
    "mf = os.path.abspath(\"../models/mobilenet_streamline.onnx\")\n",
    "model = ModelWrapper(mf)\n",
    "# model = model.transform(DoubleToSingleFloat())\n",
    "set_multithreshold_default(model,mf.replace('.onnx',\"_ort.onnx\"))\n",
    "\n",
    "# Set up a session for \n",
    "so = ort.SessionOptions()\n",
    "so.register_custom_ops_library(get_library_path())\n",
    "sess = ort.InferenceSession(mf.replace('.onnx',\"_ort.onnx\"), so)\n",
    "print(sess.get_inputs()[0].shape)\n",
    "\n",
    "for k,v in model_dict.items():\n",
    "    data_dir = v[\"data_dir\"]\n",
    "#     x = np.load(f\"{data_dir}/{k}_input.npy\")\n",
    "    x = np.random.random([1,3,224,224])\n",
    "    inp_dict = {sess.get_inputs()[0].name: x.astype(np.float32)}\n",
    "    _gld_res = sess.run([],inp_dict)\n",
    "    print(_gld_res)\n",
    "    np.save(f\"{data_dir}/{k}_gld_output.npy\",_gld_res)\n",
    "#     ! ls {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c2ca76",
   "metadata": {},
   "source": [
    "# Perform the hardware run for the dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0cddc7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- Conv_6 ----------------------------------------\n",
      "(1, 56, 56, 128)\n",
      "---------------------------------------- Conv_10 ----------------------------------------\n",
      "(1, 28, 28, 256)\n",
      "---------------------------------------- Conv_0 ----------------------------------------\n",
      "(1, 111, 111, 32)\n",
      "---------------------------------------- Conv_2 ----------------------------------------\n",
      "(1, 111, 111, 64)\n",
      "---------------------------------------- Conv_4 ----------------------------------------\n",
      "(1, 56, 56, 128)\n",
      "---------------------------------------- Conv_8 ----------------------------------------\n",
      "(1, 28, 28, 256)\n"
     ]
    }
   ],
   "source": [
    "for k,v in model_dict.items():\n",
    "    print_name(k)\n",
    "    x = os.path.join(v['data_dir'],f\"{k}_input.npy\")\n",
    "    y = os.path.join(v['data_dir'],f\"{k}_hw_output.npy\")\n",
    "#     ! ls {v[\"bitfile_dir\"]}\n",
    "    x_hw = np.load(x).reshape((1, 224, 224, 3))\n",
    "    x_hw_f =os.path.join(v['data_dir'],f\"{k}_hw_input.npy\") \n",
    "    np.save(x_hw_f,x_hw)\n",
    "    if not os.path.isfile(y):\n",
    "        ! python {v[\"driver_dir\"]}/driver.py --inputfile={x_hw_f} --outputfile={y} --bitfile={v[\"bitfile_dir\"]}/finn-accel.bit\n",
    "    y_hw = np.load(y)\n",
    "    print(y_hw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9de6b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in model_dict.items():\n",
    "#     Get hw output\n",
    "    y_hw = np.load(v['data_dir'] + f'/{k}_hw_output.npy')\n",
    "#     Create a ort session\n",
    "    mf = v['model_dir']+'/partition_1.onnx'\n",
    "    mf_update = mf.replace('.onnx','_ort.onnx')\n",
    "\n",
    "    set_multithreshold_default(ModelWrapper(mf),mf_update)\n",
    "\n",
    "    so = ort.SessionOptions()\n",
    "    \n",
    "    so.register_custom_ops_library(get_library_path())\n",
    "    sess = ort.InferenceSession(mf_update, so)\n",
    "    x_cpu = y_hw.reshape(sess.get_inputs()[0].shape)\n",
    "    inp_dict = {sess.get_inputs()[0].name: x_cpu}\n",
    "    y = sess.run([],inp_dict)\n",
    "    np.save(os.path.join(v['data_dir'],f\"{k}_output.npy\"),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c039d6f8",
   "metadata": {},
   "source": [
    "# Functional verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c09724c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- Conv_6 ----------------------------------------\n",
      "[[[644 818 626 530 111]]] [[[753 905 828 904 556]]]\n",
      "---------------------------------------- Conv_10 ----------------------------------------\n",
      "[[[644 818 626 530 111]]] [[[794 828 906 591 549]]]\n",
      "---------------------------------------- Conv_0 ----------------------------------------\n",
      "[[[644 818 626 530 111]]] [[[644 818 111 626 530]]]\n",
      "---------------------------------------- Conv_2 ----------------------------------------\n",
      "[[[644 818 626 530 111]]] [[[904 905 794 619 669]]]\n",
      "---------------------------------------- Conv_4 ----------------------------------------\n",
      "[[[644 818 626 530 111]]] [[[588 904 828 858 794]]]\n",
      "---------------------------------------- Conv_8 ----------------------------------------\n",
      "[[[644 818 626 530 111]]] [[[530 539 688 646 885]]]\n"
     ]
    }
   ],
   "source": [
    "for k,v in model_dict.items():\n",
    "#     ! ls {v['data_dir']}\n",
    "    out = v['data_dir']+f\"/{k}_output.npy\"\n",
    "    gld = v['data_dir']+f\"/{k}_gld_output.npy\"\n",
    "    print_name(k)\n",
    "    gld = np.load(gld)\n",
    "    out = np.load(out)\n",
    "    print(gld,out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
