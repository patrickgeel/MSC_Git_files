{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bd89c3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/juypter_notebooks', '/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/src/qonnx', '/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/src/finn', '/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/src', '/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/src/qonnx', '/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/src/finn', '/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/src', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/share/pynq-venv/lib/python3.10/site-packages', '/usr/local/lib/python3.10/dist-packages', '/usr/local/lib/python3.10/dist-packages/onnx-1.12.0-py3.10-linux-aarch64.egg', '/usr/local/lib/python3.10/dist-packages/typing_extensions-4.4.0-py3.10.egg', '/usr/local/lib/python3.10/dist-packages/qonnx-0.0.0-py3.10.egg', '/usr/local/lib/python3.10/dist-packages/toposort-1.7-py3.10.egg', '/usr/local/lib/python3.10/dist-packages/sigtools-2.0.3-py3.10.egg', '/usr/local/lib/python3.10/dist-packages/onnxruntime_extensions-0.5.0+1762059-py3.10-linux-aarch64.egg', '/usr/lib/python3/dist-packages', '/usr/lib/python3.10/dist-packages', '/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/build-KV260/Conv/Conv_6_out0/driver']\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import os\n",
    "# sys.path = []\n",
    "sys.path.insert(1,os.path.abspath(\"../src/\"))\n",
    "sys.path.insert(1,os.path.abspath(\"../src/finn/\"))\n",
    "sys.path.insert(1,os.path.abspath(\"../src/qonnx/\"))\n",
    "print(sys.path)\n",
    "clean_sys_path = sys.path\n",
    "\n",
    "def print_name(key):\n",
    "    print(\"--\"*20,key, \"--\"*20)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddec9c0",
   "metadata": {},
   "source": [
    "# Create dummy inputs and store in the correct model directory \n",
    "For the moment want to create dummy input data, and keep this constant such that it does not change. Use this data to verify that the hw + cpu run has the same output as the expected output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "06dc8f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- Conv_6_out0 ----------------------------------------\n",
      "bitfile  driver\t\t   partition_0_ort.onnx  partition_1_ort.onnx\n",
      "data\t partition_0.onnx  partition_1.onnx\n",
      "---------------------------------------- Conv_10_out0 ----------------------------------------\n",
      "bitfile  driver\t\t   partition_0_ort.onnx  partition_1_ort.onnx\n",
      "data\t partition_0.onnx  partition_1.onnx\n",
      "---------------------------------------- Conv_0_out0 ----------------------------------------\n",
      "bitfile  driver\t\t   partition_0_ort.onnx  partition_1_ort.onnx\n",
      "data\t partition_0.onnx  partition_1.onnx\n",
      "---------------------------------------- Conv_2_out0 ----------------------------------------\n",
      "bitfile  driver\t\t   partition_0_ort.onnx  partition_1_ort.onnx\n",
      "data\t partition_0.onnx  partition_1.onnx\n",
      "---------------------------------------- Conv_4_out0 ----------------------------------------\n",
      "bitfile  driver\t\t   partition_0_ort.onnx  partition_1_ort.onnx\n",
      "data\t partition_0.onnx  partition_1.onnx\n",
      "---------------------------------------- Conv_8_out0 ----------------------------------------\n",
      "bitfile  driver\t\t   partition_0_ort.onnx  partition_1_ort.onnx\n",
      "data\t partition_0.onnx  partition_1.onnx\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "clear_data = False\n",
    "\n",
    "# Create a directory with relative info\n",
    "model_dict = {}\n",
    "\n",
    "# Get the onnx model directory\n",
    "md = os.path.abspath(\"../models\")\n",
    "op_type = \"Conv\"\n",
    "\n",
    "# Get the model hw directory where the driver file is located.\n",
    "build_dir = os.path.abspath(\"../build-KV260/\")\n",
    "\n",
    "# Get split names for created hw files\n",
    "split_dirs = [s for s in os.listdir(os.path.join(build_dir,op_type))]\n",
    "\n",
    "# Fill the model dict\n",
    "for split_name in split_dirs:\n",
    "    print_name(split_name)\n",
    "    model_base_folder = os.path.join(md,op_type,split_name)\n",
    "    driver_dir = os.path.join(model_base_folder,\"driver\")\n",
    "    bitfile_dir = os.path.join(model_base_folder,\"bitfile\")\n",
    "    data_dir = os.path.join(model_base_folder,\"data\")\n",
    "    if clear_data:\n",
    "        try:\n",
    "            shutil.rmtree(data_dir)\n",
    "            shutil.rmtree(bitfile_dir)\n",
    "            shutil.rmtree(driver_dir)\n",
    "        except OSError as e:\n",
    "            pass        \n",
    "    else:\n",
    "        shutil.copytree(os.path.join(build_dir,op_type,split_name,\"deploy\"),\n",
    "                        model_base_folder, \n",
    "                        dirs_exist_ok=True\n",
    "                       )\n",
    "        \n",
    "    ! ls {model_base_folder}\n",
    "    model_dict[split_name.replace('_out0','')] = {\"model_dir\": model_base_folder, \n",
    "                                                  \"driver_dir\": driver_dir, \n",
    "                                                  \"bitfile_dir\":bitfile_dir,\n",
    "                                                  \"data_dir\": data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957c181d",
   "metadata": {},
   "source": [
    "##### Eventually want to supply a image and see the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2249e336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_6_input.npy\n",
      "Conv_10_input.npy\n",
      "Conv_0_input.npy\n",
      "Conv_2_input.npy\n",
      "Conv_4_input.npy\n",
      "Conv_8_input.npy\n"
     ]
    }
   ],
   "source": [
    "# Create dummy data for the moment\n",
    "for k,v in model_dict.items():\n",
    "    sd = v[\"data_dir\"]\n",
    "    if not os.path.exists(sd):\n",
    "        os.mkdir(sd)\n",
    "        x = np.ones([1,3,224,224])\n",
    "        np.save(f\"{sd}/{k}_input.npy\",x)\n",
    "        v[\"data_dir\"] = sd\n",
    "    ! ls {v[\"data_dir\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a240b91",
   "metadata": {},
   "source": [
    "# Get golden output \n",
    "For each of the inputs get the expected output from the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9d4388f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 224, 224]\n",
      "Conv_6_gld_output.npy  Conv_6_input.npy\n",
      "Conv_10_gld_output.npy\tConv_10_input.npy\n",
      "Conv_0_gld_output.npy  Conv_0_input.npy\n",
      "Conv_2_gld_output.npy  Conv_2_input.npy\n",
      "Conv_4_gld_output.npy  Conv_4_input.npy\n",
      "Conv_8_gld_output.npy  Conv_8_input.npy\n"
     ]
    }
   ],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from onnxruntime_extensions import get_library_path\n",
    "import onnxruntime as ort\n",
    "from custom_ort_functions import set_multithreshold_default\n",
    "\n",
    "# Load input streamlined model\n",
    "mf = os.path.abspath(\"../models/mobilenet_streamline.onnx\")\n",
    "model = ModelWrapper(mf)\n",
    "model = model.transform(DoubleToSingleFloat())\n",
    "set_multithreshold_default(model,mf.replace('.onnx',\"_ort.onnx\"))\n",
    "\n",
    "# Set up a session for \n",
    "so = ort.SessionOptions()\n",
    "so.register_custom_ops_library(get_library_path())\n",
    "sess = ort.InferenceSession(mf.replace('.onnx',\"_ort.onnx\"), so)\n",
    "print(sess.get_inputs()[0].shape)\n",
    "\n",
    "for k,v in model_dict.items():\n",
    "    data_dir = v[\"data_dir\"]\n",
    "    x = np.load(f\"{data_dir}/{k}_input.npy\")\n",
    "    inp_dict = {sess.get_inputs()[0].name: x.astype(np.float32)}\n",
    "    _gld_res = sess.run([],inp_dict)\n",
    "    print(_gld_res)\n",
    "    np.save(f\"{data_dir}/{k}_gld_output.npy\",_gld_res)\n",
    "#     ! ls {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c2ca76",
   "metadata": {},
   "source": [
    "# Perform the hardware run for the dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7421350d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- Conv_6 ----------------------------------------\n",
      "(1, 56, 56, 128)\n",
      "---------------------------------------- Conv_10 ----------------------------------------\n",
      "(1, 28, 28, 256)\n",
      "---------------------------------------- Conv_0 ----------------------------------------\n",
      "(1, 111, 111, 32)\n",
      "---------------------------------------- Conv_2 ----------------------------------------\n",
      "(1, 111, 111, 64)\n",
      "---------------------------------------- Conv_4 ----------------------------------------\n",
      "(1, 56, 56, 128)\n",
      "---------------------------------------- Conv_8 ----------------------------------------\n",
      "(1, 28, 28, 256)\n"
     ]
    }
   ],
   "source": [
    "for k,v in model_dict.items():\n",
    "    print_name(k)\n",
    "    x = os.path.join(v['data_dir'],f\"{k}_input.npy\")\n",
    "    y = os.path.join(v['data_dir'],f\"{k}_hw_output.npy\")\n",
    "#     ! ls {v[\"bitfile_dir\"]}\n",
    "    x_hw = np.load(x).reshape((1, 224, 224, 3))\n",
    "    x_hw_f =os.path.join(v['data_dir'],f\"{k}_hw_input.npy\") \n",
    "    np.save(x_hw_f,x_hw)\n",
    "    if not os.path.isfile(y):\n",
    "        ! python {v[\"driver_dir\"]}/driver.py --inputfile={x_hw_f} --outputfile={y} --bitfile={v[\"bitfile_dir\"]}/finn-accel.bit\n",
    "    y_hw = np.load(y)\n",
    "    print(y_hw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49e7f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.datatype import DataType\n",
    "from driver_base import FINNExampleOverlay\n",
    "\n",
    "io_shape_dict = {\n",
    "    # FINN DataType for input and output tensors\n",
    "    \"idt\" : [DataType['UINT8']],\n",
    "    \"odt\" : [DataType['INT24']],\n",
    "    # shapes for input and output tensors (NHWC layout)\n",
    "    \"ishape_normal\" : [(1, 224, 224, 3)],\n",
    "    \"oshape_normal\" : [(1, 111, 111, 32)],\n",
    "    # folded / packed shapes below depend on idt/odt and input/output\n",
    "    # PE/SIMD parallelization settings -- these are calculated by the\n",
    "    # FINN compiler.\n",
    "    \"ishape_folded\" : [(1, 224, 224, 3, 1)],\n",
    "    \"oshape_folded\" : [(1, 111, 111, 2, 16)],\n",
    "    \"ishape_packed\" : [(1, 224, 224, 3, 1)],\n",
    "    \"oshape_packed\" : [(1, 111, 111, 2, 48)],\n",
    "    \"input_dma_name\" : ['idma0'],\n",
    "    \"output_dma_name\" : ['odma0'],\n",
    "    \"number_of_external_weights\": 0,\n",
    "    \"num_inputs\" : 1,\n",
    "    \"num_outputs\" : 1,\n",
    "}\n",
    "\n",
    "\n",
    "def exe_mode(batch_size = 1,\n",
    "    bitfile = \"../bitfile/finn-accel.bit\",\n",
    "    inputfile = \"input.npy\",\n",
    "    outputfile = \"output.npy\",\n",
    "    runtime_weight_dir = \"runtime_weights/\",\n",
    "    io_shape_dict = None\n",
    "            ):\n",
    "        platform = \"zynq-iodma\"\n",
    "        accel = FINNExampleOverlay(\n",
    "        bitfile_name = bitfile, platform = platform,\n",
    "        io_shape_dict = io_shape_dict, batch_size = batch_size,\n",
    "        runtime_weight_dir = runtime_weight_dir\n",
    "        )\n",
    "        print(io_shape_dict)\n",
    "     # load desired input .npy file(s)\n",
    "        ibuf_normal = []\n",
    "        for ifn in [inputfile]:\n",
    "            ibuf_normal.append(np.load(ifn))\n",
    "        obuf_normal = accel.execute(ibuf_normal)\n",
    "        if not isinstance(obuf_normal, list):\n",
    "            obuf_normal = [obuf_normal]\n",
    "        for o, obuf in enumerate(obuf_normal):\n",
    "            np.save(outputfile, obuf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b24599aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Conv_6 --------------------\n",
      "/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/build-KV260/Conv/Conv_6_out0/driver/driver.py\n",
      "[(1, 56, 56, 128)]\n",
      "-------------------- Conv_10 --------------------\n",
      "/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/build-KV260/Conv/Conv_6_out0/driver/driver.py\n",
      "[(1, 56, 56, 128)]\n",
      "-------------------- Conv_0 --------------------\n",
      "/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/build-KV260/Conv/Conv_6_out0/driver/driver.py\n",
      "[(1, 56, 56, 128)]\n",
      "-------------------- Conv_2 --------------------\n",
      "/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/build-KV260/Conv/Conv_6_out0/driver/driver.py\n",
      "[(1, 56, 56, 128)]\n",
      "-------------------- Conv_4 --------------------\n",
      "/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/build-KV260/Conv/Conv_6_out0/driver/driver.py\n",
      "[(1, 56, 56, 128)]\n",
      "-------------------- Conv_8 --------------------\n",
      "/home/root/jupyter_notebooks/MSC_Git_files/mobilenet_v1/build-KV260/Conv/Conv_6_out0/driver/driver.py\n",
      "[(1, 56, 56, 128)]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "exe = False\n",
    "past_driver = ''\n",
    "for k,v in model_dict.items():\n",
    "    print(\"-\"*20,k,\"-\"*20)\n",
    "    \n",
    "    hw_deploy_dir = v[\"hw_deploy_dir\"]  \n",
    "    driver_dir = os.path.abspath(os.path.join(hw_deploy_dir,\"../driver\"))\n",
    "#     print(driver_dir)\n",
    "    sys.path.append(driver_dir)\n",
    "    import driver    \n",
    "#     io_shape_dict = PACKAGE.io_shape_dict\n",
    "    if driver.__file__ != past_driver:\n",
    "        import driver    \n",
    "        past_driver = driver.__file__\n",
    "    print(driver.__file__)\n",
    "\n",
    "    io_shape_dict = driver.io_shape_dict\n",
    "        \n",
    "#     print(io_shape_dict.__file__)\n",
    "    print(io_shape_dict['oshape_normal'])\n",
    "\n",
    "    \n",
    "    data_dir = v[\"data_dir\"]\n",
    "    # Load and reshape the input\n",
    "    x = np.load(f\"{data_dir}/{k}_input.npy\")\n",
    "    x = x.reshape(io_shape_dict[\"ishape_normal\"][0])\n",
    "    x = x.astype(np.uint8)\n",
    "    # Save the reshaped data for hw input\n",
    "    np.save(f\"{data_dir}/{k}_hw_input.npy\",x)\n",
    "    # execute hw run \n",
    "#     print(f\"{data_dir}/{k}_hw_output.npy\")\n",
    "#     if os.path.exists(f\"{data_dir}\"):\n",
    "#         for f in os.listdir(f\"{data_dir}\"):\n",
    "#             if f\"{k}_hw_output.npy\" == f:\n",
    "#                 exe = False\n",
    "    if exe:\n",
    "        exe_mode(bitfile=f\"{hw_deploy_dir}/bitfile/finn-accel.bit\",\n",
    "                 inputfile=f\"{data_dir}/{k}_hw_input.npy\",\n",
    "                 outputfile=f\"{data_dir}/{k}_hw_output.npy\")\n",
    "    sys.path.remove(driver_dir)\n",
    "# print(sys.path)\n",
    "# sys.path = clean_sys_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9de6b474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 111, 111, 32) [1, 128, 56, 56]\n",
      "(1, 111, 111, 32) [1, 256, 28, 28]\n",
      "(1, 111, 111, 32) [1, 32, 111, 111]\n",
      "(1, 111, 111, 32) [1, 64, 111, 111]\n",
      "(1, 111, 111, 32) [1, 128, 56, 56]\n",
      "(1, 111, 111, 32) [1, 256, 28, 28]\n"
     ]
    }
   ],
   "source": [
    "for k,v in model_dict.items():\n",
    "#     Get hw output\n",
    "    y_hw = np.load(v['data_dir'] + f'/{k}_hw_output.npy')\n",
    "#     Create a ort session\n",
    "    mf = v['model_dir']+'/partition_1.onnx'\n",
    "    mf_update = mf.replace('.onnx','_ort.onnx')\n",
    "\n",
    "    set_multithreshold_default(ModelWrapper(mf),mf_update)\n",
    "\n",
    "    so = ort.SessionOptions()\n",
    "    \n",
    "    so.register_custom_ops_library(get_library_path())\n",
    "    sess = ort.InferenceSession(mf_update, so)\n",
    "    print(y_hw.shape,sess.get_inputs()[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
