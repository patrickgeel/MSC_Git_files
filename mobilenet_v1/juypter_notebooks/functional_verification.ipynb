{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4eed8713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.insert(1,\"../src/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee816da7",
   "metadata": {},
   "source": [
    "# Create dummy inputs and store in the correct model directory \n",
    "For the moment want to create dummy input data, and keep this constant such that it does not change. Use this data to verify that the hw + cpu run has the same output as the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f4b4f46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition_0.onnx  partition_1.onnx\n",
      "partition_0.onnx  partition_1.onnx\n",
      "partition_0.onnx  partition_1.onnx\n",
      "partition_0.onnx  partition_1.onnx\n",
      "partition_0.onnx  partition_1.onnx\n",
      "partition_0.onnx  partition_1.onnx\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "clear_data = False\n",
    "\n",
    "# Create a directory with relative info\n",
    "model_dict = {}\n",
    "\n",
    "# Get the onnx model directory\n",
    "md = \"../models\"\n",
    "op_type = \"Conv\"\n",
    "\n",
    "# Get the model hw directory where the driver file is located.\n",
    "build_dir = \"../build-KV260/\"\n",
    "\n",
    "# Get split names for created hw files\n",
    "split_dirs = [s for s in os.listdir(os.path.join(build_dir,op_type))]\n",
    "\n",
    "# Fill the model dict\n",
    "for split_name in split_dirs:\n",
    "    hw_base_folder = os.path.join(build_dir,op_type,split_name,\"deploy\")\n",
    "    model_base_folder = os.path.join(md,op_type,split_name)\n",
    "    if clear_data:\n",
    "        shutil.rmtree(f\"{model_base_folder}/data\")\n",
    "    ! ls {model_base_folder}\n",
    "    model_dict[split_name] = {\"model_dir\": model_base_folder, \"hw_dir\": hw_base_folder}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4b283222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy data for the moment\n",
    "for k,v in model_dict.items():\n",
    "    sd = v[\"model_dir\"] + \"/data\"\n",
    "    if not os.path.exists(sd):\n",
    "        os.mkdir(sd)\n",
    "        x = np.random.random([1,3,224,224])\n",
    "        np.save(f\"{sd}/{k}_input.npy\",x)\n",
    "        v[\"data_dir\"] = sd\n",
    "    else:\n",
    "        v[\"data_dir\"] = sd\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2149d80b",
   "metadata": {},
   "source": [
    "# Get golden output \n",
    "For each of the inputs get the expected output from the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "048892d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_dir': '../models/Conv/Conv_6_out0', 'hw_dir': '../build-KV260/Conv/Conv_6_out0/deploy', 'data_dir': '../models/Conv/Conv_6_out0/data'}\n",
      "(1, 3, 224, 224)\n",
      "{'model_dir': '../models/Conv/Conv_10_out0', 'hw_dir': '../build-KV260/Conv/Conv_10_out0/deploy', 'data_dir': '../models/Conv/Conv_10_out0/data'}\n",
      "(1, 3, 224, 224)\n",
      "{'model_dir': '../models/Conv/Conv_0_out0', 'hw_dir': '../build-KV260/Conv/Conv_0_out0/deploy', 'data_dir': '../models/Conv/Conv_0_out0/data'}\n",
      "(1, 3, 224, 224)\n",
      "{'model_dir': '../models/Conv/Conv_2_out0', 'hw_dir': '../build-KV260/Conv/Conv_2_out0/deploy', 'data_dir': '../models/Conv/Conv_2_out0/data'}\n",
      "(1, 3, 224, 224)\n",
      "{'model_dir': '../models/Conv/Conv_4_out0', 'hw_dir': '../build-KV260/Conv/Conv_4_out0/deploy', 'data_dir': '../models/Conv/Conv_4_out0/data'}\n",
      "(1, 3, 224, 224)\n",
      "{'model_dir': '../models/Conv/Conv_8_out0', 'hw_dir': '../build-KV260/Conv/Conv_8_out0/deploy', 'data_dir': '../models/Conv/Conv_8_out0/data'}\n",
      "(1, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from onnxruntime_extensions import get_library_path\n",
    "import onnxruntime as ort\n",
    "from custom_ort_functions import set_multithreshold_default\n",
    "# TODO: ADD THIS STEP TO THE CUSTOM_ORT_FUNCTIONS\n",
    "from qonnx.transformation.double_to_single_float import DoubleToSingleFloat\n",
    "\n",
    "# Load input streamlined model\n",
    "mf = \"../models/mobilenet_streamline.onnx\"\n",
    "model = ModelWrapper(mf)\n",
    "model = model.transform(DoubleToSingleFloat())\n",
    "set_multithreshold_default(model,mf.replace('.onnx',\"_ort.onnx\"))\n",
    "\n",
    "so = ort.SessionOptions()\n",
    "so.register_custom_ops_library(get_library_path())\n",
    "sess = ort.InferenceSession(mf.replace('.onnx',\"_ort.onnx\"), so)\n",
    "\n",
    "inp_shape = sess.get_inputs()[0].shape\n",
    "inp_name = sess.get_inputs()[0].name\n",
    "inp_type = sess.get_inputs()[0].type\n",
    "\n",
    "dtype = \"\"\n",
    "if \"float\" in inp_type:\n",
    "    dtype = np.float32\n",
    "elif \"int\" in inp_type:\n",
    "    dtype = np.int\n",
    "    \n",
    "    \n",
    "for k,v in model_dict.items():\n",
    "    print(v)\n",
    "    data_dir = v[\"data_dir\"]\n",
    "    x = np.load(f\"{data_dir}/{k}_input.npy\")\n",
    "    print(x.shape)\n",
    "    inp_dict = {inp_name: x.astype(np.float32)}\n",
    "\n",
    "# res = sess.run([],inp_dict)\n",
    "# res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
