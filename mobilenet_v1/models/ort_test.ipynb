{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09afa86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "import onnxruntime as ort\n",
    "from qonnx.transformation.create_generic_partitions import PartitionFromDict\n",
    "from onnx import helper\n",
    "from onnxruntime_extensions import get_library_path\n",
    "from qonnx.util.basic import get_by_name\n",
    "from onnx import checker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6dc669c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/qonnx-0.0.0-py3.10.egg/qonnx/core/modelwrapper.py:93: UserWarning: Some old-style domain attributes were automatically converted to new-style,\n",
      "                i.e. domain=finn to domain=qonnx.custom_op.<general|fpgadataflow|...>\n",
      "  warnings.warn(\n",
      "2022-11-30 11:10:50.293508777 [E:onnxruntime:, inference_session.cc:1500 operator()] Exception during initialization: No attribute with name:'out_scale'is defined.\n"
     ]
    },
    {
     "ename": "RuntimeException",
     "evalue": "[ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: No attribute with name:'out_scale'is defined.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeException\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m so \u001b[38;5;241m=\u001b[39m ort\u001b[38;5;241m.\u001b[39mSessionOptions()\n\u001b[1;32m     25\u001b[0m so\u001b[38;5;241m.\u001b[39mregister_custom_ops_library(get_library_path())\n\u001b[0;32m---> 27\u001b[0m sess \u001b[38;5;241m=\u001b[39m \u001b[43mort\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInferenceSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmfile_up\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mso\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/pynq-venv/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:347\u001b[0m, in \u001b[0;36mInferenceSession.__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m disabled_optimizers \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_inference_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisabled_optimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "File \u001b[0;32m/usr/local/share/pynq-venv/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:395\u001b[0m, in \u001b[0;36mInferenceSession._create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    392\u001b[0m     disabled_optimizers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(disabled_optimizers)\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# initialize the C++ InferenceSession\u001b[39;00m\n\u001b[0;32m--> 395\u001b[0m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisabled_optimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess \u001b[38;5;241m=\u001b[39m sess\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess\u001b[38;5;241m.\u001b[39msession_options\n",
      "\u001b[0;31mRuntimeException\u001b[0m: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: No attribute with name:'out_scale'is defined."
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(\"mobilenetv1-w4a4_pre_post_tidy.onnx\")\n",
    "stop_node = [n for n in model.graph.node if n.op_type == \"QuantAvgPool2d\"]\n",
    "stop_node[0].input[0]\n",
    "\n",
    "up = model.find_upstream(stop_node[0].input[0], lambda x: x.name == \"Div_0\")\n",
    "wanted, unwanted = [],[]\n",
    "for ind,n in enumerate(model.graph.node):\n",
    "    \n",
    "    if get_by_name(up,n.name,\"name\")is not None:\n",
    "        wanted.append(ind)\n",
    "    else:\n",
    "        unwanted.append(ind)\n",
    "\n",
    "parent = model.transform(PartitionFromDict(partitioning={0:wanted,1:unwanted},partition_dir=\"test\"))\n",
    "parent.save(\"test/test.onnx\")\n",
    "\n",
    "mfile = 'test/partition_0.onnx'\n",
    "model = ModelWrapper(mfile)\n",
    "for n in model.graph.node:\n",
    "    if n.domain == \"qonnx.custom_op.general\":\n",
    "        n.domain = \"ai.onnx.contrib\"\n",
    "mfile_up = mfile.replace('.onnx',\"_ort.onnx\")\n",
    "model.save(mfile_up)\n",
    "so = ort.SessionOptions()\n",
    "so.register_custom_ops_library(get_library_path())\n",
    "\n",
    "sess = ort.InferenceSession(mfile_up, so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a80a94c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 1\n"
     ]
    }
   ],
   "source": [
    "mfile = \"estimate/Mul/Mul_0_out0/partition_1.onnx\"\n",
    "mfile_up = mfile.replace(\".onnx\",\"_ort.onnx\")\n",
    "\n",
    "model = ModelWrapper(mfile)\n",
    "\n",
    "node = [n for n in model.graph.node if n.op_type == 'QuantAvgPool2d'][0]\n",
    "attr = [n.attribute for n in model.graph.node if n.op_type == 'QuantAvgPool2d'][0]\n",
    "\n",
    "for a in attr:\n",
    "    if a.name == \"stride\":\n",
    "        s = a.i\n",
    "    elif a.name == \"kernel\":\n",
    "        k = a.i\n",
    "print(k,s)\n",
    "\n",
    "update = helper.make_node(\n",
    "    \"AveragePool\",\n",
    "    inputs=[node.input[0]],\n",
    "    outputs=[node.output[0]],\n",
    "    kernel_shape=[k,k],\n",
    "#     strides=[s,s],\n",
    ")\n",
    "        \n",
    "model.graph.node.remove(node)\n",
    "model.graph.node.append(update)\n",
    "\n",
    "new_attr = [helper.make_attribute(\"out_scale\", 1.0),\n",
    "            helper.make_attribute(\"out_bias\", 0.0),\n",
    "            helper.make_attribute(\"data_layout\",\"NCHW\")]\n",
    "\n",
    "for n in model.graph.node:\n",
    "    if n.op_type == \"MultiThreshold\":\n",
    "        for a in new_attr:\n",
    "            n.attribute.append(a)\n",
    "        n.domain = \"ai.onnx.contrib\"\n",
    "model.save(mfile_up)\n",
    "model = ModelWrapper(mfile_up)\n",
    "\n",
    "\n",
    "model.save(mfile_up)\n",
    "\n",
    "so = ort.SessionOptions()\n",
    "so.register_custom_ops_library(get_library_path())\n",
    "\n",
    "sess = ort.InferenceSession(mfile_up, so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6ec62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(mfile)\n",
    "for n in model.graph.node:\n",
    "    [print(n) for na in n.attribute if na.name == 'out_scale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a3ad3ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "No opset import for domain 'ai.onnx.contrib'\n\n==> Context: Bad node spec for node. Name: MultiThreshold_0 OpType: MultiThreshold",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m so \u001b[38;5;241m=\u001b[39m ort\u001b[38;5;241m.\u001b[39mSessionOptions()\n\u001b[1;32m     24\u001b[0m so\u001b[38;5;241m.\u001b[39mregister_custom_ops_library(get_library_path())\n\u001b[0;32m---> 25\u001b[0m \u001b[43mchecker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mso\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/pynq-venv/lib/python3.10/site-packages/onnx/checker.py:106\u001b[0m, in \u001b[0;36mcheck_model\u001b[0;34m(model, full_check)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mgetsizeof(protobuf_string) \u001b[38;5;241m>\u001b[39m MAXIMUM_PROTOBUF:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis protobuf of onnx model is too large (>2GB). Call check_model with model path instead.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m \u001b[43mC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotobuf_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_check:\n\u001b[1;32m    108\u001b[0m     onnx\u001b[38;5;241m.\u001b[39mshape_inference\u001b[38;5;241m.\u001b[39minfer_shapes(model, check_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, strict_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValidationError\u001b[0m: No opset import for domain 'ai.onnx.contrib'\n\n==> Context: Bad node spec for node. Name: MultiThreshold_0 OpType: MultiThreshold"
     ]
    }
   ],
   "source": [
    "from qonnx.transformation.remove import remove_node_and_rewire\n",
    "# from qonnx.util.cleanup import cleanup_model\n",
    "model = ModelWrapper(mfile)\n",
    "node = [n for n in model.graph.node if n.op_type == 'QuantAvgPool2d'][0]\n",
    "\n",
    "remove_node_and_rewire(model,node)\n",
    "# pre.output[0] \n",
    "# pre\n",
    "# rm = []\n",
    "# for i in range(node,len(model.graph.node)):\n",
    "#     rm.append(model.graph.node[i])\n",
    "# for n in rm:\n",
    "#     model.graph.node.remove(n)\n",
    "    \n",
    "# new_out = model.get_tensor_valueinfo(pre.output[0])\n",
    "# model.graph.output.remove(model.graph.output[0])\n",
    "# model.graph.output.append(new_out)\n",
    "for n in model.graph.node:\n",
    "    if n.domain == \"qonnx.custom_op.general\":\n",
    "        n.domain = \"ai.onnx.contrib\"\n",
    "        \n",
    "model.save(mfile_up)\n",
    "so = ort.SessionOptions()\n",
    "so.register_custom_ops_library(get_library_path())\n",
    "checker.check_model(model.model,so)\n",
    "\n",
    "# sess = ort.InferenceSession(mfile_up, so)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18234fee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<onnxruntime.capi.onnxruntime_pybind11_state.ModelMetadata at 0xffff52331670>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from onnxruntime_extensions import get_library_path\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "\n",
    "mfile = \"avgpool_test.onnx\"\n",
    "mfile_up = mfile.replace('.onnx','_ort.onnx')\n",
    "model = ModelWrapper(mfile)\n",
    "\n",
    "so = ort.SessionOptions()\n",
    "so.register_custom_ops_library(get_library_path())\n",
    "for n in model.graph.node:\n",
    "    if n.domain == \"qonnx.custom_op.general\":\n",
    "        n.domain = \"ai.onnx.contrib\"\n",
    "    if n.op_type == \"QuantAvgPool2d\":\n",
    "        n.domain = ''\n",
    "model.save(mfile_up)\n",
    "\n",
    "sess = ort.InferenceSession(mfile_up, so)\n",
    "# sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5dc89b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx import helper, TensorProto, save\n",
    "\n",
    "avgpool_attributes =  {\"kernel_shape\": [3, 3]}\n",
    "avgpool_node = helper.make_node(\n",
    "    \"AveragePool\", [\"global_in\"], [\"global_out\"], name=\"avgpool_node\", **avgpool_attributes\n",
    ")\n",
    "inp_shape = [1, 3, 24, 40]\n",
    "out_shape = [1, 3, 22, 38]\n",
    "input_tensor = helper.make_tensor_value_info(\"global_in\", TensorProto.FLOAT, inp_shape)\n",
    "output_tensor = helper.make_tensor_value_info(\"global_out\", TensorProto.FLOAT, out_shape)\n",
    "\n",
    "graph = helper.make_graph(\n",
    "    [avgpool_node],\n",
    "    \"AveragePool_test_model\",\n",
    "    [input_tensor],\n",
    "    [output_tensor],\n",
    ")\n",
    "model = helper.make_model(graph, opset_imports=[helper.make_opsetid(\"\", 12)])\n",
    "model.ir_version = 7  # use stable onnx ir version\n",
    "save(model, \"avgpool_test.onnx\")\n",
    "# avgpool_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ec1884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
