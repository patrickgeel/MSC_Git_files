{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09afa86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "import onnxruntime as ort\n",
    "from qonnx.transformation.create_generic_partitions import PartitionFromDict\n",
    "from onnx import helper\n",
    "from onnxruntime_extensions import get_library_path\n",
    "from qonnx.util.basic import get_by_name\n",
    "from onnx import checker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a80a94c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 1\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "[ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Load model from estimate/Mul/Mul_0_out0/partition_1_ort.onnx failed:Invalid model. Node input 'QuantAvgPool2d_0_out0' is not a graph input, initializer, or output of a previous node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m so \u001b[38;5;241m=\u001b[39m ort\u001b[38;5;241m.\u001b[39mSessionOptions()\n\u001b[1;32m     41\u001b[0m so\u001b[38;5;241m.\u001b[39mregister_custom_ops_library(get_library_path())\n\u001b[0;32m---> 43\u001b[0m sess \u001b[38;5;241m=\u001b[39m \u001b[43mort\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInferenceSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmfile_up\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mso\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/pynq-venv/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:347\u001b[0m, in \u001b[0;36mInferenceSession.__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m disabled_optimizers \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_inference_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisabled_optimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "File \u001b[0;32m/usr/local/share/pynq-venv/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:384\u001b[0m, in \u001b[0;36mInferenceSession._create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    382\u001b[0m session_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess_options \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess_options \u001b[38;5;28;01melse\u001b[39;00m C\u001b[38;5;241m.\u001b[39mget_default_session_options()\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_path:\n\u001b[0;32m--> 384\u001b[0m     sess \u001b[38;5;241m=\u001b[39m \u001b[43mC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInferenceSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_config_from_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     sess \u001b[38;5;241m=\u001b[39m C\u001b[38;5;241m.\u001b[39mInferenceSession(session_options, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_bytes, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_config_from_model)\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Load model from estimate/Mul/Mul_0_out0/partition_1_ort.onnx failed:Invalid model. Node input 'QuantAvgPool2d_0_out0' is not a graph input, initializer, or output of a previous node."
     ]
    }
   ],
   "source": [
    "mfile = \"estimate/Mul/Mul_0_out0/partition_1.onnx\"\n",
    "mfile_up = mfile.replace(\".onnx\",\"_ort.onnx\")\n",
    "\n",
    "model = ModelWrapper(mfile)\n",
    "\n",
    "node = [n for n in model.graph.node if n.op_type == 'QuantAvgPool2d'][0]\n",
    "attr = [n.attribute for n in model.graph.node if n.op_type == 'QuantAvgPool2d'][0]\n",
    "\n",
    "for a in attr:\n",
    "    if a.name == \"stride\":\n",
    "        s = a.i\n",
    "    elif a.name == \"kernel\":\n",
    "        k = a.i\n",
    "print(k,s)\n",
    "\n",
    "update = helper.make_node(\n",
    "    \"AveragePool\",\n",
    "    inputs=[node.input[0]],\n",
    "    outputs=[node.output[0]],\n",
    "    kernel_shape=[k,k],\n",
    "#     strides=[s,s],\n",
    ")\n",
    "\n",
    "for n in model.graph.node:\n",
    "    if n.domain == \"qonnx.custom_op.general\":\n",
    "        n.domain = \"ai.onnx.contrib\"\n",
    "        \n",
    "model.graph.node.remove(node)\n",
    "# model.graph.node.append(update)\n",
    "\n",
    "model.save(mfile_up)\n",
    "\n",
    "so = ort.SessionOptions()\n",
    "so.register_custom_ops_library(get_library_path())\n",
    "\n",
    "sess = ort.InferenceSession(mfile_up, so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6ec62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(mfile)\n",
    "for n in model.graph.node:\n",
    "    [print(n) for na in n.attribute if na.name == 'out_scale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a3ad3ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "No opset import for domain 'ai.onnx.contrib'\n\n==> Context: Bad node spec for node. Name: MultiThreshold_0 OpType: MultiThreshold",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m so \u001b[38;5;241m=\u001b[39m ort\u001b[38;5;241m.\u001b[39mSessionOptions()\n\u001b[1;32m     24\u001b[0m so\u001b[38;5;241m.\u001b[39mregister_custom_ops_library(get_library_path())\n\u001b[0;32m---> 25\u001b[0m \u001b[43mchecker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mso\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/share/pynq-venv/lib/python3.10/site-packages/onnx/checker.py:106\u001b[0m, in \u001b[0;36mcheck_model\u001b[0;34m(model, full_check)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mgetsizeof(protobuf_string) \u001b[38;5;241m>\u001b[39m MAXIMUM_PROTOBUF:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis protobuf of onnx model is too large (>2GB). Call check_model with model path instead.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m \u001b[43mC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotobuf_string\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_check:\n\u001b[1;32m    108\u001b[0m     onnx\u001b[38;5;241m.\u001b[39mshape_inference\u001b[38;5;241m.\u001b[39minfer_shapes(model, check_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, strict_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValidationError\u001b[0m: No opset import for domain 'ai.onnx.contrib'\n\n==> Context: Bad node spec for node. Name: MultiThreshold_0 OpType: MultiThreshold"
     ]
    }
   ],
   "source": [
    "from qonnx.transformation.remove import remove_node_and_rewire\n",
    "# from qonnx.util.cleanup import cleanup_model\n",
    "model = ModelWrapper(mfile)\n",
    "node = [n for n in model.graph.node if n.op_type == 'QuantAvgPool2d'][0]\n",
    "\n",
    "remove_node_and_rewire(model,node)\n",
    "# pre.output[0] \n",
    "# pre\n",
    "# rm = []\n",
    "# for i in range(node,len(model.graph.node)):\n",
    "#     rm.append(model.graph.node[i])\n",
    "# for n in rm:\n",
    "#     model.graph.node.remove(n)\n",
    "    \n",
    "# new_out = model.get_tensor_valueinfo(pre.output[0])\n",
    "# model.graph.output.remove(model.graph.output[0])\n",
    "# model.graph.output.append(new_out)\n",
    "for n in model.graph.node:\n",
    "    if n.domain == \"qonnx.custom_op.general\":\n",
    "        n.domain = \"ai.onnx.contrib\"\n",
    "        \n",
    "model.save(mfile_up)\n",
    "so = ort.SessionOptions()\n",
    "so.register_custom_ops_library(get_library_path())\n",
    "checker.check_model(model.model,so)\n",
    "\n",
    "# sess = ort.InferenceSession(mfile_up, so)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18234fee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<onnxruntime.capi.onnxruntime_pybind11_state.ModelMetadata at 0xffff52331670>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from onnxruntime_extensions import get_library_path\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "\n",
    "mfile = \"avgpool_test.onnx\"\n",
    "mfile_up = mfile.replace('.onnx','_ort.onnx')\n",
    "model = ModelWrapper(mfile)\n",
    "\n",
    "so = ort.SessionOptions()\n",
    "so.register_custom_ops_library(get_library_path())\n",
    "for n in model.graph.node:\n",
    "    if n.domain == \"qonnx.custom_op.general\":\n",
    "        n.domain = \"ai.onnx.contrib\"\n",
    "    if n.op_type == \"QuantAvgPool2d\":\n",
    "        n.domain = ''\n",
    "model.save(mfile_up)\n",
    "\n",
    "sess = ort.InferenceSession(mfile_up, so)\n",
    "# sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5dc89b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx import helper, TensorProto, save\n",
    "\n",
    "avgpool_attributes =  {\"kernel_shape\": [3, 3]}\n",
    "avgpool_node = helper.make_node(\n",
    "    \"AveragePool\", [\"global_in\"], [\"global_out\"], name=\"avgpool_node\", **avgpool_attributes\n",
    ")\n",
    "inp_shape = [1, 3, 24, 40]\n",
    "out_shape = [1, 3, 22, 38]\n",
    "input_tensor = helper.make_tensor_value_info(\"global_in\", TensorProto.FLOAT, inp_shape)\n",
    "output_tensor = helper.make_tensor_value_info(\"global_out\", TensorProto.FLOAT, out_shape)\n",
    "\n",
    "graph = helper.make_graph(\n",
    "    [avgpool_node],\n",
    "    \"AveragePool_test_model\",\n",
    "    [input_tensor],\n",
    "    [output_tensor],\n",
    ")\n",
    "model = helper.make_model(graph, opset_imports=[helper.make_opsetid(\"\", 12)])\n",
    "model.ir_version = 7  # use stable onnx ir version\n",
    "save(model, \"avgpool_test.onnx\")\n",
    "# avgpool_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ec1884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
