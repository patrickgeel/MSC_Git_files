{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d3feb1e",
   "metadata": {},
   "source": [
    "# Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525a670f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import onnx\n",
    "from onnxruntime_extensions import get_library_path, PyOp, onnx_op, PyOrtFunction\n",
    "import onnxruntime as ort\n",
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from onnx.helper import make_attribute\n",
    "from driver_base import FINNExampleOverlay\n",
    "from driver import io_shape_dict\n",
    "set_pyop = False\n",
    "\n",
    "platform = \"zynq-iodma\"\n",
    "batch_size = 1\n",
    "bitfile = \"finn-accel.bit\"\n",
    "outputfile = \"output.npy\"\n",
    "runtime_weight_dir = \"runtime_weights/\"\n",
    "\n",
    "# instantiate FINN accelerator driver and pass batchsize and bitfile\n",
    "accel = FINNExampleOverlay(\n",
    "    bitfile_name = bitfile, platform = platform,\n",
    "    io_shape_dict = io_shape_dict, batch_size = batch_size,\n",
    "    runtime_weight_dir = runtime_weight_dir\n",
    ")\n",
    "\n",
    "if not set_pyop:\n",
    "    # Implement the CustomOp by decorating a function with onnx_op\n",
    "    @onnx_op(op_type=\"StreamingDataflowPartition\", inputs=[PyOp.dt_float], outputs=[PyOp.dt_float])\n",
    "    def StreamingDataflowPartition(inputs):\n",
    "        obuf_normal = accel.execute(inputs)\n",
    "        return obuf_normal.astype(np.float32)\n",
    "    set_pyop = True\n",
    "print(set_pyop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c864e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.double_to_single_float import DoubleToSingleFloat\n",
    "from onnx import helper\n",
    "\n",
    "def set_multithreshold_default(model):#,save_model):\n",
    "    '''\n",
    "    Pass a modelproto model and the save file\n",
    "    '''\n",
    "    model = model.transform(DoubleToSingleFloat())\n",
    "    new_attr = [helper.make_attribute(\"out_scale\", 1.0),\n",
    "                helper.make_attribute(\"out_bias\", 0.0),\n",
    "                helper.make_attribute(\"data_layout\",\"NCHW\")]\n",
    "\n",
    "    for n in model.graph.node:\n",
    "        if n.op_type == \"MultiThreshold\":\n",
    "            out_scale,bias,datalayout = False,False,False\n",
    "            for na in n.attribute:\n",
    "                if na.name == \"out_scale\": out_scale = True\n",
    "                if na.name == \"out_bias\": bias = True\n",
    "                if na.name == \"data_layout\": datlayout = True\n",
    "            if not out_scale: n.attribute.append(new_attr[0])\n",
    "            if not bias: n.attribute.append(new_attr[1])\n",
    "            if not datalayout: n.attribute.append(new_attr[2])\n",
    "\n",
    "            n.domain = \"ai.onnx.contrib\"\n",
    "#     model.save(save_model)\n",
    "    return model\n",
    "\n",
    "def revert_quantAvgPool(model):\n",
    "    nodes = [n for n in model.graph.node if n.op_type == 'QuantAvgPool2d']\n",
    "    attrs = [n.attribute for n in model.graph.node if n.op_type == 'QuantAvgPool2d']\n",
    "    for node,attr in zip(nodes,attrs):\n",
    "        for a in attr:\n",
    "            if a.name == \"stride\":\n",
    "                s = a.i\n",
    "            elif a.name == \"kernel\":\n",
    "                k = a.i\n",
    "        update = helper.make_node(\n",
    "            \"AveragePool\",\n",
    "            inputs=[node.input[0]],\n",
    "            outputs=[node.output[0]],\n",
    "            kernel_shape=[k,k],\n",
    "            strides=[s,s],\n",
    "        )\n",
    "\n",
    "        model.graph.node.remove(node)\n",
    "        model.graph.node.append(update)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80655f47",
   "metadata": {},
   "source": [
    "## HW session for partition_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b10b7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.load(\"dog.npy\")\n",
    "\n",
    "model_func = PyOrtFunction.from_model(\"./dataflow_parent_updated.onnx\")\n",
    "outputs = model_func(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a768244",
   "metadata": {},
   "source": [
    "## Continue with the output and pass to the ORT instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5643c245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 09:25:43.599345820 [W:onnxruntime:, graph.cc:107 MergeShapeInfo] Error merging shape info for output. 'QuantAvgPool2d_0_out0' source:{1,7,1,1018} target:{1,1,1,1024}. Falling back to lenient merge.\n",
      "2022-12-16 09:25:43.795555139 [E:onnxruntime:, sequential_executor.cc:369 Execute] Non-zero status code returned while running MatMul node. Name:'MatMul_0' Status Message: matmul_helper.h:61 Compute MatMul dimension mismatch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 512, 14, 14]] (1, 512, 14, 14)\n"
     ]
    },
    {
     "ename": "Fail",
     "evalue": "[ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running MatMul node. Name:'MatMul_0' Status Message: matmul_helper.h:61 Compute MatMul dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFail\u001b[0m                                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m inp_shape \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m sess\u001b[38;5;241m.\u001b[39mget_inputs()]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(inp_shape,outputs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 15\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m{\u001b[49m\u001b[43minp_name\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(res)\n\u001b[1;32m     17\u001b[0m y\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/usr/local/share/pynq-venv/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:200\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    198\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[0;31mFail\u001b[0m: [ONNXRuntimeError] : 1 : FAIL : Non-zero status code returned while running MatMul node. Name:'MatMul_0' Status Message: matmul_helper.h:61 Compute MatMul dimension mismatch"
     ]
    }
   ],
   "source": [
    "model = ModelWrapper(\"./partition_1.onnx\")\n",
    "\n",
    "so = ort.SessionOptions()\n",
    "so.register_custom_ops_library(get_library_path())\n",
    "\n",
    "model = revert_quantAvgPool(model)\n",
    "model = set_multithreshold_default(model)\n",
    "sess = ort.InferenceSession(model.model.SerializeToString(),so)\n",
    "\n",
    "inp_name = [i.name for i in sess.get_inputs()]\n",
    "inp_shape = [i.shape for i in sess.get_inputs()]\n",
    "\n",
    "print(inp_shape,outputs.shape)\n",
    "\n",
    "# res = sess.run([],{inp_name[0]:outputs})\n",
    "# y = np.array(res)\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba48f3e4",
   "metadata": {},
   "source": [
    "## Compare the two outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6d0f26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU and HW output are the same!\n"
     ]
    }
   ],
   "source": [
    "equal = np.testing.assert_array_almost_equal(y[0],outputs)\n",
    "if equal == None:\n",
    "    print(\"CPU and HW output are the same!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
